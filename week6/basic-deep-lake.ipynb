{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8ff994-3f5a-4ac6-875c-1e0b497be464",
   "metadata": {},
   "source": [
    "##  Setup: Deep Lake in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b75e7e1-d501-4ba0-a7ec-c30c28600a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc2f66-d39b-46d2-ab4f-7a026e310e5f",
   "metadata": {},
   "source": [
    "### Step 1: Import Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9519ae23-6c30-459c-b6c8-417507793d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84df4e-616c-4bed-b7e4-5aecabd94ad8",
   "metadata": {},
   "source": [
    "###  Step 2: Create a New Dataset (Local/Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa665088-ea44-4529-8915-b59361e74e37",
   "metadata": {},
   "outputs": [
    {
     "ename": "LogExistsError",
     "evalue": "Dataset already exists at path 'mem://tiny_dataset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogExistsError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create an in-memory dataset\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m ds \u001b[38;5;241m=\u001b[39m deeplake\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem://tiny_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create tensors\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ds\u001b[38;5;241m.\u001b[39mcreate_tensor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, htype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLogExistsError\u001b[0m: Dataset already exists at path 'mem://tiny_dataset/'"
     ]
    }
   ],
   "source": [
    "# Create a simple Deep Lake dataset (in-memory)\n",
    "import deeplake\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Create an in-memory dataset\n",
    "ds = deeplake.create(\"mem://tiny_dataset\")\n",
    "\n",
    "# Create tensors\n",
    "ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpeg\")\n",
    "ds.create_tensor(\"labels\", htype=\"class_label\", class_names=[\"red\", \"blue\"])\n",
    "\n",
    "# Add samples\n",
    "for i in range(6):\n",
    "    color = \"red\" if i < 3 else \"blue\"\n",
    "    rgb = [255, 0, 0] if color == \"red\" else [0, 0, 255]\n",
    "    img = Image.new(\"RGB\", (32, 32), tuple(rgb))\n",
    "    ds.append({\"images\": img, \"labels\": color})\n",
    "\n",
    "# Commit the changes\n",
    "ds.commit(\"Initial simple dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9db86bd3-d3f5-41f5-8ef8-f1c2da35cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from deeplake.types import ClassLabel, Array\n",
    "\n",
    "# Define schema correctly\n",
    "schema = {\n",
    "    \"labels\": ClassLabel(dtype=\"int64\"),  # Store labels as integers\n",
    "    \"values\": Array(shape=(3,), dtype=\"float32\")  # Array type for values\n",
    "}\n",
    "\n",
    "# Create dataset using the correct function\n",
    "ds = deeplake.create(\"mem://tiny_dataset5\", schema=schema)\n",
    "#ds = deeplake.memory_dataset(schema=schema)\n",
    "\n",
    "# Mapping class names to indices\n",
    "class_mapping = {\"cat\": 0, \"dog\": 1}\n",
    "\n",
    "# Add entries using numeric labels\n",
    "ds.append({\"labels\": [class_mapping[\"cat\"]], \"values\": [[0.1, 0.2, 0.3]]})\n",
    "ds.append({\"labels\": [class_mapping[\"dog\"]], \"values\": [[0.4, 0.5, 0.6]]})\n",
    "\n",
    "\n",
    "# Commit changes\n",
    "ds.commit(\"Initial insert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f371596d-7718-450b-b900-854e8e390ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training data\n",
    "## Challenge: could you find this in the other notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86feb73a-1773-4657-846f-353c91182539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Array', 'BM25', 'Binary', 'BinaryMask', 'Bool', 'BoundingBox', 'Bytes', 'ClassLabel', 'Clustered', 'ClusteredQuantized', 'DataType', 'Dict', 'Embedding', 'EmbeddingIndex', 'EmbeddingIndexEnumType', 'EmbeddingIndexType', 'EmbeddingsMatrixIndex', 'EmbeddingsMatrixIndexType', 'Float16', 'Float32', 'Float64', 'Image', 'IndexType', 'Int16', 'Int32', 'Int64', 'Int8', 'Inverted', 'Link', 'Medical', 'Point', 'Polygon', 'QuantizationType', 'SegmentMask', 'Sequence', 'Struct', 'Text', 'TextIndex', 'TextIndexEnumType', 'TextIndexType', 'Type', 'TypeKind', 'UInt16', 'UInt32', 'UInt64', 'UInt8', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import deeplake.types\n",
    "print(dir(deeplake.types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ac465-c471-4982-baf4-7511117df59d",
   "metadata": {},
   "source": [
    "### Step 3: Add Some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba18db0-efa4-4ae6-b143-171b48f6090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 3 records\n",
    "# Append records one by one\n",
    "ds.append({\"labels\": [0], \"values\": [[5]]})\n",
    "ds.append({\"labels\": [1], \"values\": [[10]]})\n",
    "ds.append({\"labels\": [0], \"values\": [[15]]})\n",
    "\n",
    "# Commit the current state (like Git commit)\n",
    "ds.commit(\"Initial version: 3 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dff79-d87a-4d68-b704-19e4859063fa",
   "metadata": {},
   "source": [
    "### Step 4: Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06c7062a-04cf-416a-a330-6bb954c9c364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 0 1 0]\n",
      "Values: [array([0.1, 0.2, 0.3], dtype=float32), array([0.4, 0.5, 0.6], dtype=float32), array([5.], dtype=float32), array([10.], dtype=float32), array([15.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\", ds[\"labels\"][:])\n",
    "print(\"Values:\", ds[\"values\"][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e661cd-5c68-403f-8194-211b4863d864",
   "metadata": {},
   "source": [
    "### Step 5: Make a Change (add one more item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1598badc-530a-4fdb-b921-8c658ed99951",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.append({\"labels\": [1], \"values\": [[20]]})  # Wrap values in nested list\n",
    "ds.commit(\"Added 4th sample (dog, 20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1b0af-a5f6-4e3a-a424-c6c2527d3371",
   "metadata": {},
   "source": [
    "### Step 6: View Commit History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "919a8927-29e0-41a1-b987-0b67dfb5ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000v00000000 2025-05-07 19:03:25 Dataset created\n",
      "0000000001m00000000 2025-05-07 19:03:25 Created initial schema\n",
      "0000000002m00000000 2025-05-07 19:03:25 Initial insert\n",
      "0000000003m00000000 2025-05-07 19:08:25 Initial version: 3 samples\n",
      "0000000004m00000000 2025-05-07 19:11:22 Added 4th sample (dog, 20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239205a-d2e8-42b9-b2b0-a27bec2c6788",
   "metadata": {},
   "source": [
    "### Step 7: Checkout Older Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "057031b0-70c3-4d39-8f4e-62e83df8c993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version:\n",
      "Labels: [0 1 0 1 0 1]\n",
      "Values: [array([0.1, 0.2, 0.3], dtype=float32), array([0.4, 0.5, 0.6], dtype=float32), array([5.], dtype=float32), array([10.], dtype=float32), array([15.], dtype=float32), array([20.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Show current (latest) state\n",
    "print(\"Current version:\")\n",
    "print(\"Labels:\", ds[\"labels\"][:])\n",
    "print(\"Values:\", ds[\"values\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f499aa5-4933-4d1f-bca5-84e6bebeea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 6\n",
      "Columns:\n",
      "  labels: kind=class_label, dtype=int64\n",
      "  values: array(dtype=float32, shape=(3))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58fbc584-43c1-498c-97c5-6fa3add49d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After checkout to first version:\n",
      "Labels: [0 1 0 1 0 1]\n",
      "Values: [array([0.1, 0.2, 0.3], dtype=float32), array([0.4, 0.5, 0.6], dtype=float32), array([5.], dtype=float32), array([10.], dtype=float32), array([15.], dtype=float32), array([20.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Labels:\", ds[\"labels\"][:])\n",
    "print(\"Values:\", ds[\"values\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aeecf1c4-f579-40fc-a4cf-745f21970ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(ds, \"checkout\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2c867-c3dc-4624-9aa8-7d5ecaf90b4f",
   "metadata": {},
   "source": [
    "### Step 8: Switch Back to Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d909e7cd-ced1-496c-9b08-21e53f23890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to latest version:\n",
      "Labels: [0 1]\n",
      "Values: [[0.1 0.2 0.3]\n",
      " [0.4 0.5 0.6]]\n"
     ]
    }
   ],
   "source": [
    "#ds.checkout(\"active\")\n",
    "#print(\"Back to latest version:\")\n",
    "#print(\"Labels:\", ds.labels[:])\n",
    "print(\"Back to latest version:\")\n",
    "print(\"Labels:\", ds[\"labels\"][:])\n",
    "print(\"Values:\", ds[\"values\"][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e78232-51a6-4677-8e79-a08e9bd8504c",
   "metadata": {},
   "source": [
    "### Save Dataset Locally or to Deep Lake Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a7788-b532-45b8-8381-00fccd3ef947",
   "metadata": {},
   "source": [
    " To save to local disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b905da13-658f-47af-9831-51f4dd0376b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgreementError', 'AgreementNotAcceptedError', 'Any', 'AuthenticationError', 'AuthorizationError', 'BadRequestError', 'Branch', 'BranchExistsError', 'BranchNotFoundError', 'BranchView', 'Branches', 'BranchesView', 'BytePositionIndexOutOfChunk', 'Callable', 'CanNotCreateTensorWithProvidedCompressions', 'CannotDeleteMainBranchError', 'CannotRenameMainBranchError', 'Client', 'Column', 'ColumnAlreadyExistsError', 'ColumnDefinition', 'ColumnDefinitionView', 'ColumnDoesNotExistError', 'ColumnMissingAppendValueError', 'ColumnView', 'CredsKeyAlreadyAssignedError', 'Dataset', 'DatasetUnavailableError', 'DatasetView', 'Dict', 'DimensionsMismatch', 'DtypeMismatch', 'EmbeddingSizeMismatch', 'Executor', 'ExpiredTokenError', 'FormatNotSupportedError', 'Future', 'FutureVoid', 'GcsStorageProviderFailed', 'HTTPBodyIsMissingError', 'HTTPBodyIsNotJSONError', 'HTTPRequestFailedError', 'History', 'IncorrectDeeplakePathError', 'IndexAlreadyExistsError', 'IndexingMode', 'InvalidBinaryMaskCompression', 'InvalidChunkStrategyType', 'InvalidColumnValueError', 'InvalidCredsKeyAssignmentError', 'InvalidImageCompression', 'InvalidIndexCreationError', 'InvalidLinkDataError', 'InvalidLinkType', 'InvalidMedicalCompression', 'InvalidPolygonShapeError', 'InvalidSegmentMaskCompression', 'InvalidSequenceOfSequence', 'InvalidTextType', 'InvalidType', 'InvalidTypeAndFormatPair', 'InvalidTypeDimensions', 'JSONIndexNotFound', 'JSONKeyNotFound', 'LogExistsError', 'LogNotexistsError', 'Metadata', 'NotFoundError', 'NotLoggedInAgreementError', 'Optional', 'PushError', 'Random', 'ReadOnlyDataset', 'ReadOnlyDatasetModificationError', 'ReadOnlyMetadata', 'Row', 'RowRange', 'RowRangeView', 'RowView', 'Schema', 'SchemaView', 'ShapeIndexOutOfChunk', 'StorageAccessDenied', 'StorageInternalError', 'StorageKeyAlreadyExists', 'StorageKeyNotFound', 'StorageNetworkConnectionError', 'Tag', 'TagExistsError', 'TagNotFoundError', 'TagView', 'Tags', 'TagsView', 'TelemetryClient', 'TensorAlreadyExists', 'UnevenColumnsError', 'UnevenUpdateError', 'UnexpectedInputDataForDicomColumn', 'UnexpectedMedicalTypeInputData', 'UnknownBoundingBoxCoordinateFormat', 'UnknownBoundingBoxPixelFormat', 'UnknownFormat', 'UnknownStringType', 'UnknownType', 'UnspecifiedDtype', 'UnsupportedChunkCompression', 'UnsupportedPythonType', 'UnsupportedSampleCompression', 'Version', 'VersionNotFoundError', 'WriteFailedError', 'WrongChunkCompression', 'WrongSampleCompression', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__register_at_fork', '__spec__', '__version__', '_deeplake', '_pytorch', '_tensorflow', 'client', 'connect', 'convert', 'copy', 'core', 'create', 'create_async', 'deeplake', 'delete', 'disconnect', 'empty', 'exists', 'from_coco', 'from_parquet', 'ingestion', 'like', 'load', 'numpy', 'open', 'open_async', 'open_read_only', 'open_read_only_async', 'os', 'prepare_query', 'progress_bar', 'query', 'query_async', 'random', 'schemas', 'storage', 'telemetry_client', 'tql', 'types']\n"
     ]
    }
   ],
   "source": [
    "#Challange: who can save the data on disk? (Hint: https://docs.deeplake.ai/4.0/api/dataset/)\n",
    "print(dir(deeplake))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5bab6-3984-4c12-aad8-1fb54ce322ef",
   "metadata": {},
   "source": [
    " To use the Deep Lake Hub, (We could not try it yet, because we do not have login yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12fc3f-759b-44c7-9412-add52fee4955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1869d86-70ff-4cc0-847b-ea6c22f3f17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPRequestFailedError",
     "evalue": "Method failed: GET resource: /api/org/<username>/ds/tiny_dataset5/creds?no_cache=True message: Can't fetch resource - https://app.activeloop.ai/api/org/<username>/ds/tiny_dataset5/creds?no_cache=True  ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPRequestFailedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds\u001b[38;5;241m.\u001b[39mpush(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhub://<username>/tiny_dataset5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mHTTPRequestFailedError\u001b[0m: Method failed: GET resource: /api/org/<username>/ds/tiny_dataset5/creds?no_cache=True message: Can't fetch resource - https://app.activeloop.ai/api/org/<username>/ds/tiny_dataset5/creds?no_cache=True  "
     ]
    }
   ],
   "source": [
    "ds.push(\"hub://<username>/tiny_dataset5\") # (Requires login via deeplake.login() first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98ae5d-9b15-45e4-930d-f3ca104295a7",
   "metadata": {},
   "source": [
    " If you want to access existing dataset OR one may also follow: https://docs.deeplake.ai/4.0/api/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad563-17cd-4dc4-a517-21de4b83b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "# Create a local Deep Lake dataset\n",
    "path = \"/path/to/local/directory\"\n",
    "ds = deeplake.dataset(path)\n",
    "\n",
    "# Append data to the dataset\n",
    "ds[\"image\"].append(...)\n",
    "ds[\"label\"].append(...)\n",
    "\n",
    "# Access the dataset and its tensors\n",
    "image_tensor = ds[\"image\"]\n",
    "label_tensor = ds[\"label\"]\n",
    "\n",
    "# ... perform operations on the tensors ...\n",
    "\n",
    "# Load the dataset\n",
    "ds = deeplake.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa21b04-717c-4b4e-a664-e8605cddf600",
   "metadata": {},
   "source": [
    " Follow the next Jupyter notebook from here\n",
    " AND/OR\n",
    " Problem: Time-Series Data Storage & Retrieval\n",
    "1.Gather stock price or weather data over time.\n",
    "2.Store data in Deep Lake’s optimized dataset format.\n",
    "3.Develop a query system to retrieve past trends efficiently. (For extra-points)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
